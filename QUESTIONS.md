# Q&Aカンペ（CaShield）

発表現場でそのまま使えるよう、要点だけを簡潔にまとめました。

## Q1. 要約プロンプトの工夫は？
- 役割を明示（監視AIとしての視点を固定）
- 構造化JSONで出力（ng_word/turns/summary/severity/action/comfort）
- 事実ベース・誇張禁止・丁寧なトーンを指示

## Q2. レイテンシはどのくらい？
- 入力〜VAD: 数十ms
- 文字起こし: 発話の長さに依存（数秒発話で数秒）
- LLM要約: バックグラウンドで数秒
- 体感（警告音まで）: だいたい3〜5秒

## Q3. NGワードの管理と表記ゆれ対策は？
- 語彙はテキストで管理、編集容易
- かな正規化＋類似度（部分一致）で検出
- 短すぎる語は除外、深刻度が高い語だけ警告音

## Q4. なぜこの音声処理構成？
- 低遅延な録音と軽量VADで、話している部分だけを効率処理
- リアルタイム性と安定性を最優先

## Q5. 文字起こし（ASR）の“範囲・時間”はどう決める？
- 20msの細切れで録音し、VADで「1発話」を切り出す
- 文頭/文末に前後パディング（頭切れ・語尾欠けを抑制）
- 無音が続いたら確定、長すぎる発話は安全のため強制確定
- ログは「FASTで追記→FINALで同じIDを上書き確定」
- 用語: 「1発話」はVADで区切られた連続音声ひとかたまり。「2発話」はその単位を2つ分。
- 調整の目安:
  - 語尾が欠ける→後パディングを増やす／攻撃性を下げる
  - ノイズが多い→攻撃性を上げる／フレーム長を長くする
  - 遅延が気になる→パディングを少し縮める

## Q6. LLM要約の“範囲・時間”はどう決める？
- NG行を基点に、まず前後2発話（=VADユニット2つ）を初期窓にする
- 合計が最低秒数（1.5秒）に届くまで前後へ広げる
- 上限秒数（10秒）やトークン上限（1500）を超えたら端から削って収める
- NG行の時刻を“アンカー”として保持し、要約カードを原文に紐付け
- 調整の目安:
  - 文脈が足りない→最低秒数を増やす
  - 冗長→上限秒数やトークン上限を下げる
  - 文体・トーン→プロンプトの指示を調整

## Q7. なぜ Faster-Whisper を採用？ログ処理でも？
- CPU中心でも実用速度・省メモリ（int8/最適化実装）。Raspberry Pi でも現実的に動く。
- 同等精度帯で安定。GPUを前提にせず、依存が軽く配布が容易。
- FAST/FINALを同一エンジンで統一し、一貫した出力と保守性を確保（再現性・検証が楽）。
- ログ（時間制約が緩い処理）でも同じエンジンに統一することで、結果の揺れや依存の重複を避ける（学習/運用コストを削減）。
- 将来は設定だけでモデル/量子化を切替可能（柔軟に精度↔速度を選べる）。

## Q8. VADで発話を切り出す“基準”は？
- 20msごとの短い区切りで「声/無音」を判定する。
- 連続して「声」と判定された時点で発話開始。頭が欠けないように前側に少し余白（約240ms）を付ける。
- 連続して「無音」が一定時間（約500ms）続いたら発話終了。語尾が切れないように後側に余白を残す。
- 雑音環境では判定を厳しく、静かな環境では緩くできる（攻撃性の調整）。
- 異常に長い発話は安全のため一定長で区切る（フェイルセーフ）。

## Q9. 大まかなシステム構成は？
- 音声入力: マイクから低レイテンシで取り込み。
- 前処理: VADで「1発話」に切り出し（前後に少し余白）。
- 文字起こし: FASTで即時テキスト化→ログ追記→KWS→必要なら警告音。FINALで確定し、同じ行を置換・再判定。
- 検出: かな正規化＋類似度でNGを判定。短語は除外、深刻度が高い語だけ鳴動。
- 要約: 重要部分だけを抽出してLLMで要約・対応・慰めを作成し、逐次保存。
- 表示: Webで原文（追記はSSE）と要約カードを閲覧。
- 設定: すべてコード内に集約（モデル/しきい値/ビーム/鍵等）。

## Q10. 要約の構造化で、なぜJSON？（MarkdownやYAMLではなく）
- 機械可読で厳密。生成の揺れが少なく、逸脱を検知しやすい。
- 1行に収まり、JSONLとしてそのまま保存・配信しやすい（SSE/HTTPとも相性が良い）。
- 主要言語・ブラウザで標準サポートが充実。実装・保守コストが低い。
- Markdownは曖昧、YAMLはインデント依存で崩れやすい（LLM出力で誤りが出やすい）。本用途では機械処理を最優先。
